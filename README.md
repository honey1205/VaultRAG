# 📚 VaultRAG

**VaultRAG** is a powerful, privacy-focused Retrieval Augmented Generation (RAG) system designed to run entirely offline. It enables secure and intelligent question-answering over your own documents using open-source Large Language Models (LLMs)—with zero data sent to third-party services.

---

## 🚀 Key Features

✅ **Fully Offline & Private**  
Run LLMs and generate embeddings entirely on your local machine. No external API calls, no cloud, no compromises on data privacy.

✅ **Multi-Source Document Ingestion**  
Seamlessly ingest content from a variety of sources:
- 📄 Local Files (PDF, TXT, etc.)
- 🧠 GitHub Repositories
- 🌐 Websites

✅ **Streaming LLM Responses**  
Get real-time answers with streamed outputs for a smoother, faster experience.

✅ **Conversational Memory**  
Enjoy a natural, ongoing conversation with context-aware responses.

✅ **Chat Export**  
Save and revisit your Q&A sessions anytime.

---

## 🔒 Why VaultRAG?

VaultRAG is built for developers, researchers, and organizations that care deeply about:
- Data Sovereignty
- Offline Accessibility
- Open-Source Transparency

Perfect for use in research labs, regulated industries, or air-gapped environments.

---

## 📦 Coming Soon / Roadmap

- 🔍 Advanced Search & Filters  
- 🧩 Plugin System  
- 📊 Usage Analytics (local-only)  
- 📱 PWA Support  

---

## 🛠️ Getting Started

```bash
# Clone the repo
git clone https://github.com/honey1205/VaultRAG.git
cd vaultrag

# Set up the environment and install dependencies
pip install -r requirements.txt

# Run the app
streamlit run main.py
